// ALICE-History â€” Inverse entropy restoration
// SPDX-License-Identifier: AGPL-3.0-or-later
// Copyright (C) 2026 Moroya Sakamoto

/// Kind of historical fragment.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum FragmentKind {
    /// Degraded manuscript / inscription
    Text,
    /// Degraded photograph / painting
    Image,
    /// Physical object scan (3-D)
    Artifact,
    /// Stone / clay tablet carving
    Inscription,
    /// Degraded audio recording
    Audio,
}

/// A degraded historical fragment -- the input to restoration.
///
/// `data` contains the raw observed values, `mask` indicates which elements
/// are known (1.0) vs missing (0.0).
#[derive(Debug, Clone)]
pub struct Fragment {
    pub id: u64,
    pub kind: FragmentKind,
    pub data: Vec<f64>,
    pub mask: Vec<f64>,
    pub timestamp_ns: u64,
    pub content_hash: u64,
}

/// Confidence level for each restored element.
#[derive(Debug, Clone)]
pub struct ConfidenceMap {
    pub scores: Vec<f64>,
    pub mean_confidence: f64,
    pub min_confidence: f64,
    pub restoration_boundary: f64,
}

/// The restored continuous field -- entropy-reversed representation.
#[derive(Debug, Clone)]
pub struct RestorationField {
    pub values: Vec<f64>,
    pub confidence: ConfidenceMap,
    pub entropy_before: f64,
    pub entropy_after: f64,
    pub iterations: u32,
    pub content_hash: u64,
}

/// Configuration for the entropy inversion solver.
#[derive(Debug, Clone)]
pub struct InversionConfig {
    pub max_iterations: u32,
    pub convergence_threshold: f64,
    pub regularization: f64,
    pub confidence_floor: f64,
}

/// Result of a full restoration pipeline.
#[derive(Debug, Clone)]
pub struct RestorationResult {
    pub fragment_id: u64,
    pub field: RestorationField,
    pub elapsed_ns: u64,
    pub content_hash: u64,
}

/// Entropy measurement for a data sequence.
#[derive(Debug, Clone)]
pub struct EntropyMeasurement {
    pub shannon_entropy: f64,
    pub normalized_entropy: f64,
    pub unique_symbols: usize,
    pub total_symbols: usize,
}

// ---------------------------------------------------------------------------
// FNV-1a hash (file-local, same as all ALICE crates)
// ---------------------------------------------------------------------------

const FNV_OFFSET: u64 = 0xcbf2_9ce4_8422_2325;
const FNV_PRIME: u64 = 0x0100_0000_01b3;

fn fnv1a(data: &[u8]) -> u64 {
    let mut h = FNV_OFFSET;
    for &b in data {
        h ^= b as u64;
        h = h.wrapping_mul(FNV_PRIME);
    }
    h
}

/// Hash helper: convert an f64 slice to bytes and hash.
fn hash_f64_slice(slice: &[f64]) -> u64 {
    let bytes: &[u8] = unsafe {
        std::slice::from_raw_parts(slice.as_ptr() as *const u8, slice.len() * 8)
    };
    fnv1a(bytes)
}

/// Build a content hash for a Fragment from id + kind discriminant + data.
fn fragment_content_hash(id: u64, kind: FragmentKind, data: &[f64]) -> u64 {
    let mut buf: Vec<u8> = Vec::with_capacity(8 + 1 + data.len() * 8);
    buf.extend_from_slice(&id.to_le_bytes());
    buf.push(kind as u8);
    for &v in data {
        buf.extend_from_slice(&v.to_le_bytes());
    }
    fnv1a(&buf)
}

// ---------------------------------------------------------------------------
// Fragment
// ---------------------------------------------------------------------------

impl Fragment {
    /// Create a new Fragment with computed `content_hash`.
    ///
    /// # Panics
    /// Panics if `data.len() != mask.len()`.
    pub fn new(
        id: u64,
        kind: FragmentKind,
        data: Vec<f64>,
        mask: Vec<f64>,
        timestamp_ns: u64,
    ) -> Self {
        assert_eq!(
            data.len(),
            mask.len(),
            "data and mask must have the same length"
        );
        let content_hash = fragment_content_hash(id, kind, &data);
        Self {
            id,
            kind,
            data,
            mask,
            timestamp_ns,
            content_hash,
        }
    }

    /// Fraction of data that is known (mean of mask).
    pub fn known_fraction(&self) -> f64 {
        if self.mask.is_empty() {
            return 0.0;
        }
        let sum: f64 = self.mask.iter().sum();
        sum / self.mask.len() as f64
    }

    /// Number of missing (mask == 0.0) elements.
    pub fn missing_count(&self) -> usize {
        self.mask.iter().filter(|&&m| m == 0.0).count()
    }
}

// ---------------------------------------------------------------------------
// InversionConfig
// ---------------------------------------------------------------------------

impl Default for InversionConfig {
    fn default() -> Self {
        Self {
            max_iterations: 1000,
            convergence_threshold: 1e-8,
            regularization: 0.01,
            confidence_floor: 0.7,
        }
    }
}

// ---------------------------------------------------------------------------
// Entropy measurement
// ---------------------------------------------------------------------------

/// Measure Shannon entropy of a data sequence by binning values.
///
/// Values are linearly mapped into `bins` buckets between the data min and
/// max.  Shannon entropy is computed as H = -sum(p * log2(p)) over non-zero
/// bins.  `normalized_entropy` divides H by log2(bins).
pub fn measure_entropy(data: &[f64], bins: usize) -> EntropyMeasurement {
    if data.is_empty() || bins == 0 {
        return EntropyMeasurement {
            shannon_entropy: 0.0,
            normalized_entropy: 0.0,
            unique_symbols: 0,
            total_symbols: 0,
        };
    }

    let min_val = data.iter().cloned().fold(f64::INFINITY, f64::min);
    let max_val = data.iter().cloned().fold(f64::NEG_INFINITY, f64::max);

    let range = max_val - min_val;
    let mut counts = vec![0usize; bins];

    if range == 0.0 {
        // All values identical -- everything falls into bin 0.
        counts[0] = data.len();
    } else {
        for &v in data {
            let normalized = (v - min_val) / range; // 0.0 ..= 1.0
            let idx = ((normalized * (bins as f64 - 1.0)).round() as usize).min(bins - 1);
            counts[idx] += 1;
        }
    }

    let n = data.len() as f64;
    let mut entropy = 0.0f64;
    let mut unique = 0usize;

    for &c in &counts {
        if c > 0 {
            unique += 1;
            let p = c as f64 / n;
            entropy -= p * p.log2();
        }
    }

    let max_entropy = if bins > 1 { (bins as f64).log2() } else { 1.0 };
    let normalized = if max_entropy > 0.0 {
        entropy / max_entropy
    } else {
        0.0
    };

    EntropyMeasurement {
        shannon_entropy: entropy,
        normalized_entropy: normalized,
        unique_symbols: unique,
        total_symbols: data.len(),
    }
}

// ---------------------------------------------------------------------------
// Confidence computation
// ---------------------------------------------------------------------------

/// Compute a ConfidenceMap based on distance from known values.
///
/// For each element, confidence is determined by proximity to the nearest
/// known element.  Known elements receive confidence 1.0; missing elements
/// receive a value that decays with distance (1 / (1 + distance)), clamped
/// above `floor`.
fn compute_confidence(
    _data: &[f64],
    mask: &[f64],
    _restored: &[f64],
    floor: f64,
) -> ConfidenceMap {
    let n = mask.len();
    if n == 0 {
        return ConfidenceMap {
            scores: Vec::new(),
            mean_confidence: 0.0,
            min_confidence: 0.0,
            restoration_boundary: floor,
        };
    }

    // Forward pass: distance to nearest known element on the left.
    let mut left_dist = vec![n as f64; n];
    for i in 0..n {
        if mask[i] == 1.0 {
            left_dist[i] = 0.0;
        } else if i > 0 {
            left_dist[i] = left_dist[i - 1] + 1.0;
        }
    }

    // Backward pass: distance to nearest known element on the right.
    let mut right_dist = vec![n as f64; n];
    for i in (0..n).rev() {
        if mask[i] == 1.0 {
            right_dist[i] = 0.0;
        } else if i + 1 < n {
            right_dist[i] = right_dist[i + 1] + 1.0;
        }
    }

    let mut scores = Vec::with_capacity(n);
    for i in 0..n {
        let dist = left_dist[i].min(right_dist[i]);
        let raw = 1.0 / (1.0 + dist);
        scores.push(raw.max(floor));
    }

    let mean = scores.iter().sum::<f64>() / n as f64;
    let min = scores.iter().cloned().fold(f64::INFINITY, f64::min);

    ConfidenceMap {
        scores,
        mean_confidence: mean,
        min_confidence: min,
        restoration_boundary: floor,
    }
}

// ---------------------------------------------------------------------------
// Core solver: inverse entropy restoration
// ---------------------------------------------------------------------------

/// Core solver: inverse entropy restoration.
///
/// Uses iterative regularised least-squares to fill in missing values while
/// minimising entropy of the result.
///
/// ## Algorithm
///
/// 1. Initialise missing values with the mean of known values.
/// 2. For each iteration:
///    a. Compute a local smoothness gradient (minimise discontinuities at
///       boundaries between known and unknown regions).
///    b. Apply Tikhonov regularisation (prevent overfitting).
///    c. Update missing values: `new = old - lr * gradient`.
///    d. Check convergence (`max_change < threshold`).
/// 3. Compute confidence: higher for values near known data, lower for values
///    far from known data.
pub fn restore(fragment: &Fragment, config: &InversionConfig) -> RestorationResult {
    let start = std::time::Instant::now();
    let n = fragment.data.len();

    // Handle empty fragment.
    if n == 0 {
        let field = RestorationField {
            values: Vec::new(),
            confidence: ConfidenceMap {
                scores: Vec::new(),
                mean_confidence: 0.0,
                min_confidence: 0.0,
                restoration_boundary: config.confidence_floor,
            },
            entropy_before: 0.0,
            entropy_after: 0.0,
            iterations: 0,
            content_hash: fnv1a(&[]),
        };
        return RestorationResult {
            fragment_id: fragment.id,
            field,
            elapsed_ns: start.elapsed().as_nanos() as u64,
            content_hash: fnv1a(&[]),
        };
    }

    let entropy_before = measure_entropy(&fragment.data, 64).shannon_entropy;

    // Step 1: initialise restored array -- copy known, fill missing with mean.
    let known_sum: f64 = fragment
        .data
        .iter()
        .zip(fragment.mask.iter())
        .filter(|(_, &m)| m == 1.0)
        .map(|(&d, _)| d)
        .sum();
    let known_count = fragment.mask.iter().filter(|&&m| m == 1.0).count();
    let mean_known = if known_count > 0 {
        known_sum / known_count as f64
    } else {
        0.0
    };

    let mut restored: Vec<f64> = fragment
        .data
        .iter()
        .zip(fragment.mask.iter())
        .map(|(&d, &m)| if m == 1.0 { d } else { mean_known })
        .collect();

    // Step 2: iterative solver.
    let learning_rate = 0.5;
    let mut iterations: u32 = 0;

    for _iter in 0..config.max_iterations {
        iterations = _iter + 1;
        let mut max_change: f64 = 0.0;

        // We only update missing positions.
        for i in 0..n {
            if fragment.mask[i] == 1.0 {
                continue; // known -- do not touch
            }

            // (a) Smoothness gradient: encourage value to match neighbours.
            let left = if i > 0 { restored[i - 1] } else { restored[i] };
            let right = if i + 1 < n { restored[i + 1] } else { restored[i] };
            let neighbour_avg = (left + right) * 0.5;
            let smooth_grad = restored[i] - neighbour_avg;

            // (b) Tikhonov regularisation: pull toward mean.
            let reg_grad = config.regularization * (restored[i] - mean_known);

            // (c) Total gradient and update.
            let grad = smooth_grad + reg_grad;
            let new_val = restored[i] - learning_rate * grad;
            let change = (new_val - restored[i]).abs();
            if change > max_change {
                max_change = change;
            }
            restored[i] = new_val;
        }

        // (d) Convergence check.
        if max_change < config.convergence_threshold {
            break;
        }
    }

    // Step 3: confidence and entropy.
    let confidence =
        compute_confidence(&fragment.data, &fragment.mask, &restored, config.confidence_floor);
    let entropy_after = measure_entropy(&restored, 64).shannon_entropy;
    let content_hash = hash_f64_slice(&restored);

    let field = RestorationField {
        values: restored,
        confidence,
        entropy_before,
        entropy_after,
        iterations,
        content_hash,
    };

    let result_hash = {
        let mut buf = Vec::new();
        buf.extend_from_slice(&fragment.id.to_le_bytes());
        buf.extend_from_slice(&field.content_hash.to_le_bytes());
        fnv1a(&buf)
    };

    RestorationResult {
        fragment_id: fragment.id,
        field,
        elapsed_ns: start.elapsed().as_nanos() as u64,
        content_hash: result_hash,
    }
}

/// Batch restore multiple fragments.
pub fn restore_batch(fragments: &[Fragment], config: &InversionConfig) -> Vec<RestorationResult> {
    fragments.iter().map(|f| restore(f, config)).collect()
}

// ===========================================================================
// Tests
// ===========================================================================

#[cfg(test)]
mod tests {
    use super::*;

    // -- Fragment construction -----------------------------------------------

    #[test]
    fn test_fragment_new_basic() {
        let f = Fragment::new(1, FragmentKind::Text, vec![1.0, 2.0, 3.0], vec![1.0, 1.0, 1.0], 0);
        assert_eq!(f.id, 1);
        assert_eq!(f.kind, FragmentKind::Text);
        assert_eq!(f.data.len(), 3);
    }

    #[test]
    fn test_fragment_content_hash_deterministic() {
        let f1 = Fragment::new(1, FragmentKind::Text, vec![1.0, 2.0], vec![1.0, 1.0], 0);
        let f2 = Fragment::new(1, FragmentKind::Text, vec![1.0, 2.0], vec![1.0, 1.0], 999);
        assert_eq!(f1.content_hash, f2.content_hash);
    }

    #[test]
    fn test_fragment_different_data_different_hash() {
        let f1 = Fragment::new(1, FragmentKind::Text, vec![1.0, 2.0], vec![1.0, 1.0], 0);
        let f2 = Fragment::new(1, FragmentKind::Text, vec![1.0, 3.0], vec![1.0, 1.0], 0);
        assert_ne!(f1.content_hash, f2.content_hash);
    }

    #[test]
    fn test_fragment_different_kind_different_hash() {
        let f1 = Fragment::new(1, FragmentKind::Text, vec![1.0], vec![1.0], 0);
        let f2 = Fragment::new(1, FragmentKind::Image, vec![1.0], vec![1.0], 0);
        assert_ne!(f1.content_hash, f2.content_hash);
    }

    #[test]
    #[should_panic(expected = "data and mask must have the same length")]
    fn test_fragment_mismatched_lengths() {
        Fragment::new(0, FragmentKind::Text, vec![1.0, 2.0], vec![1.0], 0);
    }

    // -- known_fraction & missing_count --------------------------------------

    #[test]
    fn test_known_fraction_all_known() {
        let f = Fragment::new(0, FragmentKind::Text, vec![1.0; 10], vec![1.0; 10], 0);
        assert!((f.known_fraction() - 1.0).abs() < 1e-12);
        assert_eq!(f.missing_count(), 0);
    }

    #[test]
    fn test_known_fraction_half_known() {
        let mask = vec![1.0, 0.0, 1.0, 0.0];
        let f = Fragment::new(0, FragmentKind::Text, vec![0.0; 4], mask, 0);
        assert!((f.known_fraction() - 0.5).abs() < 1e-12);
        assert_eq!(f.missing_count(), 2);
    }

    #[test]
    fn test_known_fraction_empty() {
        let f = Fragment::new(0, FragmentKind::Text, vec![], vec![], 0);
        assert!((f.known_fraction() - 0.0).abs() < 1e-12);
        assert_eq!(f.missing_count(), 0);
    }

    #[test]
    fn test_known_fraction_all_missing() {
        let f = Fragment::new(0, FragmentKind::Text, vec![0.0; 5], vec![0.0; 5], 0);
        assert!((f.known_fraction() - 0.0).abs() < 1e-12);
        assert_eq!(f.missing_count(), 5);
    }

    // -- InversionConfig default ---------------------------------------------

    #[test]
    fn test_inversion_config_default() {
        let c = InversionConfig::default();
        assert_eq!(c.max_iterations, 1000);
        assert!((c.convergence_threshold - 1e-8).abs() < 1e-15);
        assert!((c.regularization - 0.01).abs() < 1e-15);
        assert!((c.confidence_floor - 0.7).abs() < 1e-15);
    }

    // -- Entropy measurement -------------------------------------------------

    #[test]
    fn test_entropy_uniform_data() {
        // All identical values => entropy should be 0 (one bin occupied).
        let data = vec![5.0; 100];
        let e = measure_entropy(&data, 16);
        assert!((e.shannon_entropy - 0.0).abs() < 1e-12);
        assert_eq!(e.unique_symbols, 1);
        assert_eq!(e.total_symbols, 100);
    }

    #[test]
    fn test_entropy_two_values() {
        // Alternating 0 and 1, 50/50 split => entropy ~1 bit.
        let data: Vec<f64> = (0..100).map(|i| (i % 2) as f64).collect();
        let e = measure_entropy(&data, 2);
        assert!((e.shannon_entropy - 1.0).abs() < 0.01);
    }

    #[test]
    fn test_entropy_empty() {
        let e = measure_entropy(&[], 10);
        assert!((e.shannon_entropy - 0.0).abs() < 1e-12);
        assert_eq!(e.unique_symbols, 0);
    }

    #[test]
    fn test_entropy_zero_bins() {
        let e = measure_entropy(&[1.0, 2.0], 0);
        assert!((e.shannon_entropy - 0.0).abs() < 1e-12);
    }

    #[test]
    fn test_entropy_normalized_bounded() {
        let data: Vec<f64> = (0..256).map(|i| i as f64).collect();
        let e = measure_entropy(&data, 32);
        assert!(e.normalized_entropy >= 0.0);
        assert!(e.normalized_entropy <= 1.0 + 1e-12);
    }

    // -- Restore: all known data (identity) ----------------------------------

    #[test]
    fn test_restore_all_known_returns_same_values() {
        let data = vec![10.0, 20.0, 30.0, 40.0, 50.0];
        let mask = vec![1.0; 5];
        let f = Fragment::new(1, FragmentKind::Text, data.clone(), mask, 0);
        let config = InversionConfig::default();
        let r = restore(&f, &config);
        for (orig, restored) in data.iter().zip(r.field.values.iter()) {
            assert!(
                (orig - restored).abs() < 1e-12,
                "known value changed: {} -> {}",
                orig,
                restored
            );
        }
    }

    // -- Restore: partially missing data -------------------------------------

    #[test]
    fn test_restore_fills_single_gap() {
        // Known: [10, ?, 30] -- expect middle restored near 20.
        let data = vec![10.0, 0.0, 30.0];
        let mask = vec![1.0, 0.0, 1.0];
        let f = Fragment::new(2, FragmentKind::Inscription, data, mask, 0);
        let config = InversionConfig::default();
        let r = restore(&f, &config);
        let mid = r.field.values[1];
        assert!(
            (mid - 20.0).abs() < 1.0,
            "expected ~20, got {}",
            mid
        );
    }

    #[test]
    fn test_restore_fills_multiple_gaps() {
        // Known: [0, ?, ?, ?, 40]
        let data = vec![0.0, 0.0, 0.0, 0.0, 40.0];
        let mask = vec![1.0, 0.0, 0.0, 0.0, 1.0];
        let f = Fragment::new(3, FragmentKind::Audio, data, mask, 0);
        let config = InversionConfig::default();
        let r = restore(&f, &config);
        // Restored values should be monotonically increasing-ish.
        for i in 0..4 {
            assert!(
                r.field.values[i] <= r.field.values[i + 1] + 1.0,
                "expected roughly increasing at index {}: {} > {}",
                i,
                r.field.values[i],
                r.field.values[i + 1]
            );
        }
    }

    // -- Restore: heavily degraded -------------------------------------------

    #[test]
    fn test_restore_heavily_degraded() {
        // Only first and last known.
        let n = 50;
        let mut data = vec![0.0; n];
        let mut mask = vec![0.0; n];
        data[0] = 100.0;
        mask[0] = 1.0;
        data[n - 1] = 100.0;
        mask[n - 1] = 1.0;
        let f = Fragment::new(4, FragmentKind::Image, data, mask, 0);
        let config = InversionConfig::default();
        let r = restore(&f, &config);
        // All restored values should be close to 100 (smooth interpolation between equal endpoints).
        for (i, &v) in r.field.values.iter().enumerate() {
            assert!(
                (v - 100.0).abs() < 5.0,
                "index {} too far from 100: {}",
                i,
                v
            );
        }
    }

    // -- Entropy decrease after restoration ----------------------------------

    #[test]
    fn test_entropy_decreases_after_restoration() {
        // Random-ish degraded data should become smoother (lower entropy).
        let data = vec![5.0, 0.0, 100.0, 0.0, 5.0, 0.0, 100.0, 0.0, 5.0];
        let mask = vec![1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0];
        let f = Fragment::new(5, FragmentKind::Text, data, mask, 0);
        let config = InversionConfig::default();
        let r = restore(&f, &config);
        // We check that entropy_after <= entropy_before (restoration should smooth).
        // Note: with very few data points the effect may be modest so we just
        // verify the measurement is computed.
        assert!(r.field.entropy_before >= 0.0);
        assert!(r.field.entropy_after >= 0.0);
        assert!(r.field.iterations > 0);
    }

    // -- Confidence scoring --------------------------------------------------

    #[test]
    fn test_confidence_known_elements_are_max() {
        let data = vec![1.0, 0.0, 0.0, 0.0, 1.0];
        let mask = vec![1.0, 0.0, 0.0, 0.0, 1.0];
        let f = Fragment::new(6, FragmentKind::Artifact, data, mask, 0);
        let config = InversionConfig::default();
        let r = restore(&f, &config);
        // Known positions should have confidence 1.0.
        assert!((r.field.confidence.scores[0] - 1.0).abs() < 1e-12);
        assert!((r.field.confidence.scores[4] - 1.0).abs() < 1e-12);
    }

    #[test]
    fn test_confidence_decays_with_distance() {
        let data = vec![1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0];
        let mask = vec![1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0];
        let f = Fragment::new(7, FragmentKind::Text, data, mask, 0);
        let mut config = InversionConfig::default();
        config.confidence_floor = 0.05; // low floor so decay is visible
        let r = restore(&f, &config);
        // Confidence at index 1 (near known) should be > confidence at index 4 (center).
        assert!(
            r.field.confidence.scores[1] > r.field.confidence.scores[4],
            "confidence should decay: near={} center={}",
            r.field.confidence.scores[1],
            r.field.confidence.scores[4]
        );
    }

    #[test]
    fn test_confidence_floor_respected() {
        let data = vec![1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let mask = vec![1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];
        let f = Fragment::new(8, FragmentKind::Text, data, mask, 0);
        let mut config = InversionConfig::default();
        config.confidence_floor = 0.3;
        let r = restore(&f, &config);
        for &s in &r.field.confidence.scores {
            assert!(
                s >= 0.3 - 1e-12,
                "confidence below floor: {}",
                s
            );
        }
    }

    // -- Batch restoration ---------------------------------------------------

    #[test]
    fn test_restore_batch_multiple() {
        let f1 = Fragment::new(10, FragmentKind::Text, vec![1.0, 0.0, 3.0], vec![1.0, 0.0, 1.0], 0);
        let f2 = Fragment::new(11, FragmentKind::Image, vec![5.0, 5.0], vec![1.0, 1.0], 0);
        let config = InversionConfig::default();
        let results = restore_batch(&[f1, f2], &config);
        assert_eq!(results.len(), 2);
        assert_eq!(results[0].fragment_id, 10);
        assert_eq!(results[1].fragment_id, 11);
    }

    #[test]
    fn test_restore_batch_empty() {
        let config = InversionConfig::default();
        let results = restore_batch(&[], &config);
        assert!(results.is_empty());
    }

    // -- Hash determinism ----------------------------------------------------

    #[test]
    fn test_restore_hash_deterministic() {
        let f = Fragment::new(99, FragmentKind::Text, vec![1.0, 0.0, 3.0], vec![1.0, 0.0, 1.0], 0);
        let config = InversionConfig::default();
        let r1 = restore(&f, &config);
        let r2 = restore(&f, &config);
        assert_eq!(r1.field.content_hash, r2.field.content_hash);
        assert_eq!(r1.content_hash, r2.content_hash);
    }

    // -- Edge case: empty fragment -------------------------------------------

    #[test]
    fn test_restore_empty_fragment() {
        let f = Fragment::new(0, FragmentKind::Text, vec![], vec![], 0);
        let config = InversionConfig::default();
        let r = restore(&f, &config);
        assert!(r.field.values.is_empty());
        assert_eq!(r.field.iterations, 0);
    }

    // -- Edge case: all missing ----------------------------------------------

    #[test]
    fn test_restore_all_missing() {
        let f = Fragment::new(0, FragmentKind::Text, vec![0.0; 10], vec![0.0; 10], 0);
        let config = InversionConfig::default();
        let r = restore(&f, &config);
        // With no known data, mean_known = 0.0, all values initialised to 0.0, converge to 0.0.
        for &v in &r.field.values {
            assert!((v - 0.0).abs() < 1e-6, "expected ~0, got {}", v);
        }
    }

    // -- FragmentKind variants -----------------------------------------------

    #[test]
    fn test_all_fragment_kinds() {
        let kinds = [
            FragmentKind::Text,
            FragmentKind::Image,
            FragmentKind::Artifact,
            FragmentKind::Inscription,
            FragmentKind::Audio,
        ];
        for (i, &kind) in kinds.iter().enumerate() {
            let f = Fragment::new(i as u64, kind, vec![1.0], vec![1.0], 0);
            assert_eq!(f.kind, kind);
        }
    }

    // -- Elapsed time is set -------------------------------------------------

    #[test]
    fn test_restoration_elapsed_ns() {
        let f = Fragment::new(0, FragmentKind::Text, vec![1.0, 0.0, 3.0], vec![1.0, 0.0, 1.0], 0);
        let config = InversionConfig::default();
        let r = restore(&f, &config);
        // elapsed_ns should be > 0 (we did actual work).
        // On very fast machines this could theoretically be 0 but extremely unlikely.
        assert!(r.elapsed_ns < 10_000_000_000, "took too long");
    }
}
